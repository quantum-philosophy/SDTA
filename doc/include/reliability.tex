The proposed solution of the steady-state dynamic temperature analysis can be used in a wide range of optimization procedures. One of them is the space exploration of the reliability charachteristics of embedded systems. We performing the temperature-aware mapping and scheduling in order to address the aging effect while keeping the energy consumption on an appropriate level. Both mapping and scheduling are based on genetic algorithms described in \cite{schmitz2004}. The genetic scheduling internally relies on the list scheduler.

Let us start from the overall description of the system that we use.

\subsection{Architecture Model}
We consider a multiprocessor system with heterogeneous architecture that is composed of a number of processing elements (PE). Each processing element $PE_i$ is characterized by its supply voltage $V_i$, frequency $f_i$, and the number of gates:
\begin{align*}
  & PE = \{ PE_i \} \\
  & PE_i \rightarrow (V_i, f_i, N_{gate i})
\end{align*}

\subsection{Application Model}
The system runs a periodic application $A$ which contains a number of tasks. The period of the application $T$ can be thought as a shared deadline for all the tasks. The tasks themselves and the data dependencies between them are described with a task graph:
\begin{align*}
  & A \rightarrow (G, T) \\
  & G = (\Pi, \Gamma) \\
  & \Pi = \{\tau_i\} \\
  & \Gamma = \{\gamma_i\}
\end{align*}

Each pair of a processing element $PE_i$ and a task $\tau_j$ is described by the effective switched capacitance $C_{eff \; ij}$ and the number of clock cycles $NC_{ij}$ that are requited for the given task to perform on the given core:
\begin{equation*}
  (PE_i, \tau_j) \rightarrow (C_{eff \; ij}, NC_{ij})
\end{equation*}

\subsection{Mapping and Scheduling}
We use genetic algorithms for mapping and scheduling presented in \cite{schmitz2004}.

\subsection{Power Model}
The total power consumption of a task is a sum of the dynamic power and the leakage power:
\begin{align*}
  & P = P_{dyn} + P_{leak} \\
  & P_{dyn} = C_{eff} \cdot f \cdot V_{dd}^2
\end{align*}
where $C_{eff}$ is the effective switched capacitance of a task, $V_{dd}$ and $f$ are the supplied voltage and frequency of a processing element correspondingly. For the leakage part, the model presented in \cite{liao2005} is used\footnote{Although, the leakage model can be computational intensive, the linear approximation presented in \cite{liu2007} can be used.}:
\begin{align*}
  & P_{leak} = N_{gate} \cdot I_{avg} \cdot V_{dd} \\
  & I_{avg} = I_s(T_0, V_0) \cdot f_{avg}(T, V_{dd}) \\
  & f(T, V_{dd}) = A \cdot T^2 \cdot e^{((\alpha \cdot V_{dd} + \beta)/T)} + B \cdot e^{(\gamma \cdot V_{dd} + \delta)}
\end{align*}
where $N_{gate}$ is the number of gates in the circuit,\footnote{The number of gates in a circuit can be estimated using the technique described in \cite{li2004}.} $I_s (T_0, V_0)$ is the average leakage current at the given temperature $T_0$ and supply voltage $V_0$, $f_{avg}$ is the scaling function. The last two form $I_{avg}$, the average leakage current at the current temperature $T$ and voltage $V_{dd}$. $A$, $B$, $\alpha$, $\beta$, $\gamma$, and $\delta$ are the technology dependent constants given in \cite{liao2005}.

In should be noted that the dynamic power consumption does not depend on temperature, it is a constant for each combination of a processing element with its voltage/frequency pair and a task with its effective switched capacitance. That is not the case with the leakage power.

\subsection{Temperature-Aware Reliability Optimization}
We address the thermal cycling (TC) component of the common packaging/interfacial failure mechanisms \cite{jedec2010}. The reliability model, presented in \cite{xiang2010}, is used. The number of cycles to failure ($N_{TC}$) can be estimated using a modified version of the well-known Coffin-Manson equation with the Arrhenius term \cite{jedec2010}, \cite{xiang2010}, \cite{ciappa2003}:
\begin{equation} \label{eq:cycles-to-failure}
  N = A_{TC} (\triangle T - \triangle T_0)^{-b} e^{\frac{E_{a_{TC}}}{k T_{max}}}
\end{equation}
where $A_{TC}$ is an empirically determined constant, $\triangle T$ is the thermal cycle amplitude, $\triangle T_0$ is the portion of the temperature range in the elastic region which does not cause damage, $b$ is the Coffin-Manson exponent which also empirically determined, $E_{a_{TC}}$ is the activation energy, $k$ is the Boltzmann constant, and $T_{max}$ is the maximal temperature during the thermal cycle.

The failure rate is modeled with the Weibull distribution:
\[
  R(t) = e^{(\frac{t}{\eta})^\beta}
\]
where $\eta$ is the scaling parameter, $\beta$ is the shape parameter. The last one is assumed to be constant with temperature variation, which is not the case with the scaling parameter $\eta$. Therefore, the distribution can vary from one set of conditions to another. Suppose, the overall period of the application is split into $m$ time intervals with durations $\triangle t_i = t_{i+1} - t_i$, so that on each interval the scaling parameter is constant and equal to $\eta_i$. In this case, the cumulative distribution function for the end of the first execution of the application is the following \cite{xiang2010}:
\[
  R = e^{(\sum_{i=0}^{m-1} \frac{\triangle t_i}{\eta_i})^\beta}
\]

If the period of the application is $T$, then the formula takes the following continuous form for any point of time $t$:
\[
  R(t) = e^{(\frac{t}{T} \sum_{i=0}^{m-1} \frac{\triangle t_i}{\eta_i})^\beta}
\]
where $T / \sum_{i=0}^{m-1} \frac{\triangle t_i}{\eta_i}$ and be thought as a new scaling parameter $\eta$. The mean time to failure in case of the Weibull distribution is the following:
\begin{equation} \label{eq:general-mttf}
  MTTF = \eta \cdot \Gamma(1 + \frac{1}{\beta})
\end{equation}
where $\Gamma$ is the gamma function. Now, we need to determine the scaling parameters $\eta_i$ for all time intervals. These parameters can be derived using the same \equref{eq:general-mttf}:
\[
  \eta_i = \frac{MTTF_i}{\Gamma(1 + \frac{1}{\beta})}
\]
where $MTTF_i$ is the mean time to failure for each interval (if we had the same distribution all the time), which can be modeled as a product of the average number of cycles to failure \equref{eq:cycles-to-failure} and the duration of a cycle:
\[
  MTTF_i = N_i \cdot \triangle t_i
\]

Taking everything together, we get:
\begin{align}
  MTTF & = \frac{T}{\sum_{i=0}^{m-1} \frac{\triangle t_i}{\eta_i}} \cdot \Gamma(1 + \frac{1}{\beta}) \nonumber \\
  & = \frac{T}{\Gamma(1 + \frac{1}{\beta}) \cdot \sum_{i=0}^{m-1} \frac{\triangle t_i}{\triangle t_i \cdot N_i}} \cdot \Gamma(1 + \frac{1}{\beta}) \nonumber \\
  & = \frac{T}{\sum_{i=0}^{m-1} \frac{1}{N_i}} \nonumber \\
  & = \frac{A_{TC} \cdot T}{\sum_{i=0}^{m-1} (\triangle T_i - \triangle T_0)^b e^{- \frac{E_{a_{TC}}}{k T_{max i}}}} \label{eq:one-mttf}
\end{align}

\equref{eq:one-mttf} describes the mean time to failure of one processing element. We assume that each processing element is essential for the proper work of the system, therefore, one failure of one core leads to the total failure of the whole system. Hence, the MTTF of a system with $k$ processing elements is the following:
\[
  MTTF_{total} = min_{i=0}^{k-1}(MTTF_i)
\]
