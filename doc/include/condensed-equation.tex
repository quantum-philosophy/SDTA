The system that we have is described with the following recurrent equation:
\begin{equation} \label{eq:ce-recurrent}
  Y_{i + 1} = K_i Y_i + Q_i, \; i = 0 \dots (m - 1)
\end{equation}

The iterative repetition of this equation leads us to:
\begin{align}
  Y_i & = \prod_{j = 0}^{i - 1} K_j Y_0 + P_{i - 1}, \; i = 1 \dots m \label{eq:y-recurrent} \\
  P_0 & = Q_0 \nonumber \\
  P_i & = \sum_{l = 1}^i \prod_{j = l}^i K_j Q_{l - 1} + Q_i, \: i = 1 \dots (m - 1) \nonumber
\end{align}
The last one can be rewritten as:
\begin{equation} \label{eq:p-recurrent}
  P_i = K_i P_{i - 1} + Q_i, \; i = 1 \dots (m - 1)
\end{equation}

Therefore, we can calculate the final value $Y_m$ from \equref{eq:y-recurrent}:
\[
  Y_m = \prod_{j = 0}^{m - 1} K_j Y_0 + P_{m - 1}
\]

Taking into account the boundary condition \equref{eq:boundary-condition} and substituting $Y_m$ with $Y_0$, we get the following system of linear equations:
\[
  (I - \prod_{j = 0}^{m - 1} K_j) Y_0 = P_{m - 1}
\]

To solve it, we need to obtain $P_{m - 1}$ from \eqref{eq:p-recurrent}. Once we get $Y_0$, we can use \eqref{eq:ce-recurrent} to get all other vectors $Y_i$.

Now, we know that in case of the fixed sampling interval $K_i = K$. Therefore, the equations become much simpler:
\begin{align}
  & Y_{i + 1} = K Y_i + Q_i, \; i = 0 \dots (m - 1) \nonumber \\
  & P_i = K P_{i - 1} + Q_i, \; i = 1 \dots (m - 1) \nonumber \\
  & (I - K^m) Y_0 = P_{m - 1} \label{eq:linear-system}
\end{align}

In this case, $K^m$ can be found very efficiently, since it is a power of the matrix exponential of $D t_s$ (see \equref{eq:recurrent}):
\begin{align*}
  & K = U e^{\Lambda} U^T = U \: diag(\lambda_0, \dots, \lambda_{n - 1}) \: U^T \\
  & K^m = U e^{\Lambda} U^T U e^{\Lambda} U^T \dots U e^{\Lambda} U^T = U e^{m \Lambda} U^T
\end{align*}
where:
\begin{itemize}
  \item $U$ --- a matrix of the eigenvectors of $D t_s$ (orthogonal),
  \item $\Lambda$ --- a diagonal matrix of the eigenvalues of $D t_s$.
\end{itemize}

Substituting $K^m$ from the last equation into \equref{eq:linear-system}, we get:
\[
  (I - U e^{m \Lambda} U^T) Y_0 = P_{m - 1}
\]

The identity matrix $I$ can be split into $U U^T$, therefore:
\begin{align*}
  & U (I - e^{m \Lambda}) U^T Y_0 = P_{m - 1} \\
  & Y_0 = U (I - e^{m \Lambda})^{-1} U^T P_{m - 1} \\
  & Y_0 = U M U^T P_{m - 1}
\end{align*}
where $M$ is a diagonal matrix with the following structure:
\[
  M = \left[
    \begin{array}{ccc}
      \frac{1}{1 - e^{m \lambda_0}} & \cdots & 0 \\
      \vdots & \ddots & \vdots \\
      0 & \cdots & \frac{1}{1 - e^{m \lambda_{n - 1}}}
    \end{array}
  \right]
\]

As we see, in this approach there is no need to inverse any matrix, the solution of the system is obtained by scalar divisions and a similarity transformation with $U$.

We also can benefit from the matrix exponential in the general case where the time intervals could be different:
\[
  \prod_{j = i}^l K_j = \prod_{j = i}^l e^{D t_j} = e^{D \sum_{j = i}^l t_j}
\]
since the product of each pair $D t_j$ and $D t_k$ is commutative.
