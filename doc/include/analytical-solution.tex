In order to solve the problem, we use an analytical approach. The direct solution of \equref{eq:initial} is given by the following equation:
\begin{equation} \label{eq:solution}
  T(t) = e^{C^{-1}A t} \; T_0 + (C^{-1} A)^{-1}(e^{C^{-1}A t} - I)C^{-1} B
\end{equation}

The solution provides us with the transient temperature and holds only when the power vector $B$ is constant. If it is not the case, we need to simulate shorter time intervals where this assumption can take place. Before going to the steady-state case, we perform one important adjustment to the system in order to be more efficient in our future calculations. According to \equref{eq:solution}, we need to compute the matrix exponential of the matrix $C^{-1} A t$. It would be much easier to accomplish if the matrix were symmetric, because a real symmetric matrix is \emph{diagonalizable} and has \emph{independent} (orthogonal) real eigenvectors:
\begin{equation} \label{eq:eigenvalue-decomposition}
  M = U \Lambda U^T
\end{equation}
where $M$ is a real symmetric matrix, $U$ is a square matrix of the eigenvectors of $M$, $\Lambda$ is a diagonal matrix composed of the eigenvalues of $M$ ($\lambda_i$), the equation itself is called the eigenvalue decomposition. Once we have such a decomposition, calculating the matrix exponential becomes a trivial task:
\begin{align}
  & e^M = e^{U \Lambda U^T} = U \: e^{\Lambda} \: U^T \nonumber \\
  & e^{\Lambda} = \left[
      \begin{array}{ccc}
        e^{\lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{\lambda_{n - 1}}
      \end{array}
    \right] \nonumber
\end{align}

Hence, instead of $C^{-1} A$ in front of the variable vector we want to have a symmetry matrix. In order to achieve this, we perform the following substitution:
\begin{align*}
  Y & = C^{\frac{1}{2}} T \\
  D & = C^{-\frac{1}{2}} A \: C^{-\frac{1}{2}} \\
  E & = C^{-\frac{1}{2}} B
\end{align*}
with the result:
\begin{align}
  \frac{dY}{dt} & = D \: Y + E \nonumber \\
  Y(t) & = e^{D t} Y_0 + D^{-1} (e^{D t} - I) E \label{eq:modified-solution} \\
  T(t) & = C^{-\frac{1}{2}} Y(t) \label{eq:finalization}
\end{align}

In this case, $D$ is a symmetric matrix, therefore, it will be easier to find the matrix exponential of $D \: t$ using the above-mentioned eigenvalue decomposition (\equref{eq:eigenvalue-decomposition}):
\[
  e^{D t} = U \: e^{\Lambda t} \: U^T = U \left[
      \begin{array}{ccc}
        e^{t \lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{t \lambda_{N_n - 1}}
      \end{array}
    \right] U^T
\]

Now we shift our focus at the power profile $B$ and come closer to the SSDTP. Each row of $B$ corresponds to a particular time interval $\triangle t_i$ and represents the power consumption $B_i$ during this interval of all processing elements. Each step $i = 0 \dots N_s - 1$ of the iterative process we have a pair $(\triangle t_i, B_i)$ which gives us a temperature vector $T_i$ according to \equref{eq:modified-solution} where $t = \triangle t_i$. The iterative process can be described as the following:
\begin{align}
  & Y_{i+1} = K_i \: Y_i + G_i \: B_i \label{eq:recurrent-equation} \\
  & K_i = e^{D \: \triangle t_i} \nonumber \\
  & G_i = D^{-1} \left( e^{D \triangle t_i} - I \right) C^{-\frac{1}{2}} \nonumber
\end{align}

Since we perform the eigenvalue decomposition of D (\equref{eq:eigenvalue-decomposition}), $D^{-1}$ can be efficiently computed in the following way:
\[
  D^{-1} = U \: \Lambda^{-1} \: U^T = U \left[
      \begin{array}{ccc}
        \frac{1}{\lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \frac{1}{\lambda_{N_n - 1}}
      \end{array}
    \right] U^T \\
\]
therefore:
\begin{align*}
  G_i & = U \: \Lambda^{-1} \: U^T \left(U \: e^{\Lambda \triangle t_i} \: U^T - U \: U^T \right) C^{-\frac{1}{2}} = \\
      & = U \left[
        \begin{array}{ccc}
          \frac{e^{\triangle t_i \: \lambda_0} - 1}{\lambda_0} & \cdots & 0 \\
          \vdots & \ddots & \vdots \\
          0 & \cdots & \frac{e^{\triangle t_i \: \lambda_{N_n - 1}} - 1}{\lambda_{N_n - 1}}
        \end{array}
      \right] U^T \: C^{-\frac{1}{2}}
\end{align*}

Consequently, in order to find SSDTC, we need to solve the following system of linear equations:
\[
  \begin{cases}
    K_0 \: Y_0 - Y_1 & = -Q_0 \\
    ... \\
    K_{N_s - 1} \: Y_{N_s - 1} - Y_{N_s} & = -Q_{N_s - 1}
  \end{cases}
\]
where $Q_i = G_i \: B_i$. Also we should take into account the boundary condition which ensures that the temperature has the same values on both ends of the curve:
\begin{equation} \label{eq:boundary-condition}
  Y_0 = Y_{N_s}
\end{equation}

Hence, the system of linear equations takes the following form:
\[
  \begin{cases}
    K_0 \: Y_0 - Y_1 & = -Q_0 \\
    ... \\
    -Y_0 + K_{N_s - 1} \: Y_{N_s - 1} & = -Q_{N_s - 1}
  \end{cases}
\]

To get the whole picture, the system can be written as:
\begin{align}
  & \mathbb{A} \: \mathbb{Y} = \mathbb{B} \label{eq:system} \\
  & \mathbb{A} = \left[
    \begin{array}{ccccc}
      K_0 & -I & 0 & \cdots & 0 \\
      0 & K_1 & -I &  & \vdots \\
      \vdots &  & \ddots & -I & 0 \\
      0 &  &  & K_{N_s - 2} & -I \\
      -I & 0 & \cdots & 0 & K_{N_s - 1}
    \end{array}
  \right] \nonumber \\
  & \mathbb{Y} = \left[
    \begin{array}{c}
      Y_0 \\
      \vdots \\
      Y_{N_s - 1}
    \end{array}
  \right] \nonumber \\
  & \mathbb{B} = \left[
    \begin{array}{c}
      -Q_0 \\
      \vdots \\
      -Q_{N_s - 1}
    \end{array}
  \right] \nonumber
\end{align}

where $\mathbb{A}$ is a square matrix of the dimensions $N_n N_s \times N_n N_s$. $\mathbb{Y}$ and $\mathbb{B}$ are vectors of the length $N_n N_s$.

We have obtained a regular system of liner equations with the SSDTP as its solution ($Y$ should also be processed with \equref{eq:finalization} in order to return back to $T$).

\subsection{Direct Dense Solution}
\input{include/direct-dense-solution}

\subsection{Direct Sparse Solution}
\input{include/direct-sparse-solution}

\subsection{Condensed Equation}
\input{include/condensed-equation}

\subsection{Fast Fourier Transform}
\input{include/fast-fourier-transform}

\subsection{Other solutions}
Another possible technique, that we considered but do not discuss here in details due to the shortage of space, is iterative methods for solving systems of linear systems (e.g. the Jacobi, Gaussâ€“Seidel, Successive over-relaxation methods). These methods are designed to overcome problems of direct solvers. For instance, they do not operate on full matrices and, therefore, they consume much less memory and can be applied for large systems. The most important issues with these methods are their convergence and accuracy. In our analysis we did not observe any advantages of using this methods for this particular problem, they demonstrated slow convergence and poor accuracy.
