\subsection{Problem Formulation}
We consider a multiprocessor system with a set of processing elements $\Pi = \{ \pi_i: i = 1 \dots N_p \}$. The system executes a periodic application with the overall period $\tau$ which is discretized into $N_s$ intervals $\triangle \tau = \{ \triangle \tau_j: j = 1 \dots N_s \}$. The time intervals $\triangle \tau_{ij}$ are small enough to assume that the power consumption and the temperature of each processing element $\pi_i$ are constant within these intervals. We assume that the power profile $P = \{ p_{ij}: i = 1 \dots N_p, j = 1 \dots N_s \}$, where $p_{ij}$ is the power consumption of the $i$th core during the $j$th time interval, is also periodic. After the stabilization process, the temperature profile of the system becomes periodic as well and defined as $T = \{ T_{ij}: i = 1 \dots N_p, j = 1 \dots N_s \}$, ${T_{ij}}$ corresponds to the temperature of the ${i}$th core on the $j$th time interval. Such periodic temperature profile is called the steady-state dynamic temperature curve (SSDTC).

Now we can formulate the problem. Given:
\begin{itemize}
  \item A multiprocessor system running a periodic application.
  \item The periodic power profile $P$ of the system.
  \item The floorplan of the die, i.e., the location and size of each processing element.
  \item The configuration of the package including the thermal interface material, the heat spreader, and the heat sink.
  \item The thermal parameters of the die and the package, i.e., thermal conductivity, thermal capacitance, etc.
\end{itemize}
Find:
\begin{itemize}
  \item The corresponding periodic temperature profile $T$.
\end{itemize}

Furthermore, we want to be able to perform this procedure as quick as possible with a desired accuracy in order to use it for solving different optimization problems where such temperature curves have to be calculated a very large number of times. An example of such problem is the reliability-aware task allocation and scheduling given in \secref{sec:results}.

\subsection{Iterative Solution with HotSpot}
One approach to find the SSDTC is to call the HotSpot simulator with a very long power profile composed of one repeating chunk. In this case, we get a huge temperature profile, and we can take only its tail that corresponds to the last chunk in the power profile. Another way to obtain the SSDTC is to call the simulator a number of times each time starting from the temperature that we got during the previous call.

\image{hotspot-one-realization}{50 200 50 200}{An example of one HotSpot simulation for one processing element running an application of $1 s$. The ground truth is the real steady-state dynamic temperatures curve that HotSpot is supposed to reach after a number of iterations. The power profile contains $10^4$ steps that corresponds to $10^{-4} s$ sampling interval.}

The number of iterations required to get the steady-state temperature profile depends on the accuracy that we are trying to achieve. It also depends a lot on the application itself and, consequently, on its power profile. This is an especially urgent issue for tasks that have a short execution time relative to the thermal time constant of the die. In this case temperature does not have time to reach its steady-state value during executing of a task, but it is still gradually increasing on average. This leads to a large number iterations that the simulator is required to perform. An example is given on \figref{fig:hotspot-one-realization}, where the blue curve represents the ground truth (SSDTC), and the orange one shows one first simulation of HotSpot. The sampling interval was chosen to be $10^{-4} \; s$ to capture all power fluctuations due to the task switching activity, resulting in a power profile with $10^4$ steps. The situation is getting \emph{much worse} if we want to take into consideration the leakage power, since in this case we have a loop between temperature and power, and we need to perform extra iterations (indifferent of the chosen solution approach) for temperature and power to converge \cite{liu2007}.

\subsection{Direct Analytical Solution}
In order to deal with the problem, we use an analytical approach. The direct solution of \equref{eq:initial} is given as the following:
\begin{equation} \label{eq:solution}
  T(t) = e^{C^{-1}A t} \; T_0 + (C^{-1} A)^{-1}(e^{C^{-1}A t} - I)C^{-1} B
\end{equation}

Since we want to be as efficient as possible, we shall go into details of the solution. First, we notice that here we need to calculate the matrix exponential of the matrix $C^{-1} A t$, which would be much easier to accomplish if the matrix were symmetric, because a real symmetric matrix is \emph{diagonalizable} and has \emph{independent} (orthogonal) real eigenvectors:
\begin{equation} \label{eq:eigenvalue-decomposition}
  M = U \: \Lambda \: U^T
\end{equation}
where $M$ is a real symmetric matrix, $U$ is the eigenvectors of $M$, $\Lambda$ is a diagonal matrix of the eigenvalues of $M$ ($\lambda_i$). Therefore, the matrix exponential can be computed using the obtained eigenvalue decomposition:
\begin{align}
  & e^M = e^{U \Lambda U^T} = U \: e^{\Lambda} \: U^T \nonumber \\
  & e^{\Lambda} = \left[
      \begin{array}{ccc}
        e^{\lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{\lambda_{n}}
      \end{array}
    \right] \nonumber
\end{align}

Hence, instead of $C^{-1} A t$ in front of the temperature vector we want to have a symmetry matrix. In order to achieve this, we perform the following substitution:
\begin{align*}
  Y & = C^{\frac{1}{2}} T \\
  D & = C^{-\frac{1}{2}} A \: C^{-\frac{1}{2}} \\
  E & = C^{-\frac{1}{2}} B
\end{align*}
with the result:
\begin{align}
  \frac{dY}{dt} & = D \: Y + E \nonumber \\
  Y(t) & = e^{D t} Y_0 + D^{-1} (e^{D t} - I) E \label{eq:modified-solution} \\
  T(t) & = C^{-\frac{1}{2}} Y(t) \nonumber
\end{align}

In this case, $D$ is a symmetric matrix, therefore, it will be easier to find the matrix exponential of $D \: t$ using the above-mentioned eigenvalue decomposition (\equref{eq:eigenvalue-decomposition}):
\[
  e^{D t} = U \: e^{\Lambda t} \: U^T = U \left[
      \begin{array}{ccc}
        e^{t \lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{t \lambda_{N_n}}
      \end{array}
    \right] U^T
\]

Now we are going further and look at the power profile $B$. Each row of $B$ corresponds to a particular time interval $\triangle t_i$ and represents the power consumption $B_i$ during this interval of all processing elements. Each step $i = 1 \dots N_s$ of the iterative process we have a pair $(\triangle t_i, B_i)$ which gives us a temperature vector $T_i$ according to \equref{eq:modified-solution} where $t = \triangle t_i$. The iterative process can be described as the following:
\begin{align}
  & Y_{i+1} = K_i \: Y_i + G_i \: B_i \label{eq:ce-recurrent} \\
  & K_i = e^{D \: \triangle t_i} \nonumber \\
  & G_i = D^{-1} \left( e^{D \triangle t_i} - I \right) C^{-\frac{1}{2}} \nonumber
\end{align}

Since we perform the eigenvalue decomposition of D (\equref{eq:eigenvalue-decomposition}), $D^{-1}$ can be efficiently computed in the following way:
\[
  D^{-1} = U \: \Lambda^{-1} \: U^T = U \left[
      \begin{array}{ccc}
        \frac{1}{\lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \frac{1}{\lambda_{N_n}}
      \end{array}
    \right] U^T \\
\]
therefore:
\begin{align*}
  G_i & = U \: \Lambda^{-1} \: U^T \left(U \: e^{\Lambda \triangle t_i} \: U^T - U \: U^T \right) C^{-\frac{1}{2}} = \\
      & = U \left[
        \begin{array}{ccc}
          \frac{e^{\triangle t_i \: \lambda_1} - 1}{\lambda_1} & \cdots & 0 \\
          \vdots & \ddots & \vdots \\
          0 & \cdots & \frac{e^{\triangle t_i \: \lambda_{N_n}} - 1}{\lambda_{N_n}}
        \end{array}
      \right] U^T \: C^{-\frac{1}{2}}
\end{align*}

Therefore, in order to find SSDTC, we need to solve the following system of linear equations:
\[
  \begin{cases}
    K_1 \: Y_1 - Y_2 & = -Q_1 \\
    ... \\
    K_{N_s} \: Y_{N_s} - Y_{N_s + 1} & = -Q_{N_s}
  \end{cases}
\]
where $Q_i = G_i \: B_i$. Also we should take into account the boundary condition which ensures that the temperature has the same values on both sides of the curve:
\begin{equation} \label{eq:boundary-condition}
  Y_1 = Y_{N_s + 1}
\end{equation}

Hence, the system of linear equations takes the following form:
\[
  \begin{cases}
    K_1 \: Y_1 - Y_2 & = -Q_1 \\
    ... \\
    -Y_1 + K_{N_s} \: Y_{N_s} & = -Q_{N_s}
  \end{cases}
\]

To get the whole picture, the system can be written as:
\begin{align}
  & \mathbb{A} \: \mathbb{Y} = \mathbb{B} \label{eq:system} \\
  & \mathbb{A} = \left[
    \begin{array}{ccccc}
      K_1 & -I & 0 & \cdots & 0 \\
      0 & K_2 & -I &  & \vdots \\
      \vdots &  & \ddots & -I & 0 \\
      0 &  &  & K_{N_s - 1} & -I \\
      -I & 0 & \cdots & 0 & K_{N_s}
    \end{array}
  \right] \nonumber \\
  & \mathbb{Y} = \left[
    \begin{array}{c}
      Y_1 \\
      \vdots \\
      Y_{N_s}
    \end{array}
  \right] \nonumber \\
  & \mathbb{B} = \left[
    \begin{array}{c}
      -Q_1 \\
      \vdots \\
      -Q_{N_s}
    \end{array}
  \right] \nonumber
\end{align}

$\mathbb{A}$ is a square matrix of the dimensions $N_n N_s \times N_n N_s$. $\mathbb{Y}$ and $\mathbb{B}$ are vectors of the length $N_n N_s$. This is the system that can give us the desired SSDTC.

Such systems could be extremely big, especially when we want to achieve a high level of accuracy and, therefore, the power profile contains a lot of steps $N_s$. Each new step is $N_n$ new equations in the system given by \equref{eq:system}. Also the complexity grows very rapidly with the number of processing elements $N_p$, since in the HotSpot thermal model $N_n$, the number of thermal nodes, is equal to $4 N_p + 12$ \cite{rao2008}. All in all, we need to find a fast and accurate way to solve \equref{eq:system}.

\subsection{Sampling Interval}
We make an important assumption about the time intervals $\triangle t_i$ in order to perform all the calculations in an efficient manner. We assume that \emph{the time intervals are equal}, $\triangle t_i = \triangle t$ for $i = 1 \dots N_s$, i.e., the distance in time between two successive power measurements stays constant. We refer to this distance as \emph{sampling interval}. The preferable size of this sampling interval depends on a particular application and the level of accuracy that we want to achieve. Having this assumption, the iterative process (\equref{eq:ce-recurrent}) turns into:
\[
  Y_{i+1} = K \: Y_i + G \: B_i
\]
where:
\begin{align*}
  & K = e^{D \: \triangle t} \\
  & G = D^{-1} \left( e^{D \: \triangle t} - I \right) C^{-\frac{1}{2}}
\end{align*}

It should be noted that $K$ and $G$ are constants, since they depend only on the matrices $D$, $C$, and the sampling interval $\triangle t$. Both $Y_i$ and $B_i$ are vectors of the length $N_n$. In this case, the block diagonal of the matrix $\mathbb{A}$ in \equref{eq:system} is composed of the same block: $K_i = K$ for $i = 1 \dots N_s$.

\subsection{Condensed Equation Method}
The system that we have is described with the following recurrent equation:
\begin{equation} \label{eq:recurrent}
  Y_{i + 1} = K_i \cdot Y_i + Q_i, \; i = 0 \dots (m - 1)
\end{equation}

The iterative repetition of this equation leads us to:
\begin{align}
  Y_i & = \prod_{j = 0}^{i - 1} K_j \cdot Y_0 + P_{i - 1}, \; i = 1 \dots m \label{eq:y-recurrent} \\
  P_0 & = Q_0 \nonumber \\
  P_i & = \sum_{l = 1}^i \prod_{j = l}^i K_j \cdot Q_{l - 1} + Q_i, \: i = 1 \dots (m - 1) \nonumber
\end{align}
The last one can be rewritten as:
\begin{equation} \label{eq:p-recurrent}
  P_i = K_i \cdot P_{i - 1} + Q_i, \; i = 1 \dots (m - 1)
\end{equation}

Therefore, we can calculate the final value $Y_m$ from \equref{eq:y-recurrent}:
\[
  Y_m = \prod_{j = 0}^{m - 1} K_j \cdot Y_0 + P_{m - 1}
\]

Taking into account the boundary condition \equref{eq:boundary-condition} and substituting $Y_m$ with $Y_0$, we get the following system of linear equations:
\[
  (I - \prod_{j = 0}^{m - 1} K_j) Y_0 = P_{m - 1}
\]

To solve it, we need to obtain $P_{m - 1}$ from \eqref{eq:p-recurrent}. Once we get $Y_0$, we can use \eqref{eq:recurrent} to get all other vectors $Y_i$.

Now, we know that in case of the fixed sampling interval $K_i = K$. Therefore, the equations become much simpler:
\begin{align}
  & Y_{i + 1} = K \cdot Y_i + Q_i, \; i = 0 \dots (m - 1) \nonumber \\
  & P_i = K \cdot P_{i - 1} + Q_i, \; i = 1 \dots (m - 1) \nonumber \\
  & (I - K^m) Y_0 = P_{m - 1} \label{eq:linear-system}
\end{align}

In this case, $K^m$ can be found very efficiently, since it is a power of the matrix exponential of $D t_s$ (see \equref{eq:ce-recurrent}):
\begin{align*}
  & K = U \cdot e^{\Lambda} \cdot U^T = U \cdot diag(\lambda_0, \dots, \lambda_{n - 1}) \cdot U^T \\
  & K^m = U \cdot e^{\Lambda} \cdot U^T \cdot U e^{\Lambda} \cdot U^T \dots U \cdot e^{\Lambda} \cdot U^T = U \cdot e^{m \Lambda} \cdot U^T
\end{align*}
where $U$ is a matrix of the eigenvectors of $D t_s$ (orthogonal), $\Lambda$ is a diagonal matrix of the eigenvalues of $D t_s$.

Substituting $K^m$ from the last equation into \equref{eq:linear-system}, we get:
\[
  (I - U \cdot e^{m \cdot \Lambda} \cdot U^T) Y_0 = P_{m - 1}
\]

The identity matrix $I$ can be split into $U U^T$, therefore:
\begin{align*}
  & U (I - e^{m \cdot \Lambda}) U^T \cdot Y_0 = P_{m - 1} \\
  & Y_0 = U (I - e^{m \cdot \Lambda})^{-1} U^T \cdot P_{m - 1} \\
  & Y_0 = U \cdot M \cdot U^T \cdot P_{m - 1}
\end{align*}
where $M$ is a diagonal matrix with the following structure:
\[
  M = \left[
    \begin{array}{ccc}
      \frac{1}{1 - e^{m \cdot \lambda_0}} & \cdots & 0 \\
      \vdots & \ddots & \vdots \\
      0 & \cdots & \frac{1}{1 - e^{m \cdot \lambda_{n - 1}}}
    \end{array}
  \right]
\]

As we see, in this approach there is no need to inverse any matrix, the solution of the system is obtained by scalar divisions and a similarity transformation with $U$.

We also can benefit from the matrix exponential in the general case where the time intervals could be different:
\[
  \prod_{j = i}^l K_j = \prod_{j = i}^l e^{D \cdot t_j} = e^{D \sum_{j = i}^l t_j}
\]
since the product of each pair $D \cdot t_j$ and $D \cdot t_k$ is commutative.
