\subsection{Problem Formulation}
We consider a multiprocessor system-on-chip with a set of processing elements $\Pi = \{ \pi_i: i = 1 \dots N_p \}$. The system executes a periodic application with the overall period $\mathcal{T}$ which is discretized into $N_s$ intervals $\triangle t_j$ for $j = 1 \dots N_s$. The time intervals $\triangle t_j$ are small enough to assume that the power consumption and the temperature of each processing element $\Pi_i$ are constant within these intervals. We assume that the power profile $P = \{ P_{ij}: i = 1 \dots N_p, \; j = 1 \dots N_s \}$, where $P_{ij}$ is the power consumption of the $i$th core during the $j$th time interval, is also periodic. After the stabilization process, the temperature profile of the system becomes periodic as well and defined as $T = \{ T_{ij}: i = 1 \dots N_p, \; j = 1 \dots N_s \}$, ${T_{ij}}$ corresponds to the temperature of the ${i}$th core on the $j$th time interval. Such periodic temperature profile is called the steady-state dynamic temperature curve (SSDTC).

Now we can formulate the problem. Given:
\begin{itemize}
  \item A \emph{periodic} power profile $P$ of a multiprocessor system-on-chip with a set of processing elements $\Pi$.
  \item The floorplan of the chip, i.e., the location and size of each processing element $\pi_i \in \Pi$.
  \item The configuration of the package including the thermal interface material, heat spreader, and heat sink.
  \item The thermal parameters of the die and package (the thermal conductivity, thermal capacitance, etc.).
\end{itemize}
Find:
\begin{itemize}
  \item The corresponding \emph{periodic} temperature profile $T$ of the system in its steady state (when the temperature stabilization process is finished).
\end{itemize}

Furthermore, we want to be able to perform this procedure as quick as possible with a desired accuracy in order to use it for solving different optimization problems where such temperature curves have to be calculated a very large number of times. An example of such problem is the reliability-aware task allocation and scheduling given in \secref{sec:results}.

\subsection{Iterative Solution with HotSpot}
One approach to find the SSDTC is to call the HotSpot simulator with a very long power profile composed of one repeating chunk. In this case, we get a huge temperature profile, and we can take only its tail that corresponds to the last chunk in the power profile. Another way to obtain the SSDTC is to call the simulator a number of times each time starting from the temperature that we got during the previous call.

\image{hotspot-one-realization}{50 200 50 200}{An example of one HotSpot simulation for one processing element running an application of $1 s$. The ground truth is the real steady-state dynamic temperatures curve that HotSpot is supposed to reach after a number of iterations. The power profile contains $10^4$ steps that corresponds to $10^{-4} s$ sampling interval.}

The number of iterations required to get the steady-state temperature profile depends on the accuracy that we are trying to achieve. It also depends a lot on the application itself and, consequently, on its power profile. This is an especially urgent issue for tasks that have a short execution time relative to the thermal time constant of the die. In this case temperature does not have time to reach its steady-state value during executing of a task, but it is still gradually increasing on average. This leads to a large number iterations that the simulator is required to perform. An example is given on \figref{fig:hotspot-one-realization}, where the blue curve represents the ground truth (SSDTC), and the orange one shows one first simulation of HotSpot. The sampling interval was chosen to be $10^{-4} \; s$ to capture all power fluctuations due to the task switching activity, resulting in a power profile with $10^4$ steps. The situation is getting \emph{much worse} if we want to take into consideration the leakage power, since in this case we have a loop between temperature and power, and we need to perform extra iterations (indifferent of the chosen solution approach) for temperature and power to converge \cite{liu2007}.

\subsection{Direct Analytical Solution}
In order to deal with the problem, we use an analytical approach. The direct solution of \equref{eq:initial} is given as the following:
\begin{equation} \label{eq:solution}
  T(t) = e^{C^{-1}A t} \; T_0 + (C^{-1} A)^{-1}(e^{C^{-1}A t} - I)C^{-1} B
\end{equation}

Since we want to be as efficient as possible, we shall go into details of the solution. First, we notice that here we need to calculate the matrix exponential of the matrix $C^{-1} A t$, which would be much easier to accomplish if the matrix were symmetric, because a real symmetric matrix is \emph{diagonalizable} and has \emph{independent} (orthogonal) real eigenvectors:
\begin{equation} \label{eq:eigenvalue-decomposition}
  M = U \Lambda U^T
\end{equation}
where $M$ is a real symmetric matrix, $U$ is the eigenvectors of $M$, $\Lambda$ is a diagonal matrix of the eigenvalues of $M$ ($\lambda_i$). Therefore, the matrix exponential can be computed using the obtained eigenvalue decomposition:
\begin{align}
  & e^M = e^{U \Lambda U^T} = U \: e^{\Lambda} \: U^T \nonumber \\
  & e^{\Lambda} = \left[
      \begin{array}{ccc}
        e^{\lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{\lambda_{n}}
      \end{array}
    \right] \nonumber
\end{align}

Hence, instead of $C^{-1} A t$ in front of the temperature vector we want to have a symmetry matrix. In order to achieve this, we perform the following substitution:
\begin{align*}
  Y & = C^{\frac{1}{2}} T \\
  D & = C^{-\frac{1}{2}} A \: C^{-\frac{1}{2}} \\
  E & = C^{-\frac{1}{2}} B
\end{align*}
with the result:
\begin{align}
  \frac{dY}{dt} & = D \: Y + E \nonumber \\
  Y(t) & = e^{D t} Y_0 + D^{-1} (e^{D t} - I) E \label{eq:modified-solution} \\
  T(t) & = C^{-\frac{1}{2}} Y(t) \nonumber
\end{align}

In this case, $D$ is a symmetric matrix, therefore, it will be easier to find the matrix exponential of $D \: t$ using the above-mentioned eigenvalue decomposition (\equref{eq:eigenvalue-decomposition}):
\[
  e^{D t} = U \: e^{\Lambda t} \: U^T = U \left[
      \begin{array}{ccc}
        e^{t \lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{t \lambda_{N_n}}
      \end{array}
    \right] U^T
\]

Now we are going further and look at the power profile $B$. Each row of $B$ corresponds to a particular time interval $\triangle t_i$ and represents the power consumption $B_i$ during this interval of all processing elements. Each step $i = 1 \dots N_s$ of the iterative process we have a pair $(\triangle t_i, B_i)$ which gives us a temperature vector $T_i$ according to \equref{eq:modified-solution} where $t = \triangle t_i$. The iterative process can be described as the following:
\begin{align}
  & Y_{i+1} = K_i \: Y_i + G_i \: B_i \label{eq:recurrent-equation} \\
  & K_i = e^{D \: \triangle t_i} \nonumber \\
  & G_i = D^{-1} \left( e^{D \triangle t_i} - I \right) C^{-\frac{1}{2}} \nonumber
\end{align}

Since we perform the eigenvalue decomposition of D (\equref{eq:eigenvalue-decomposition}), $D^{-1}$ can be efficiently computed in the following way:
\[
  D^{-1} = U \: \Lambda^{-1} \: U^T = U \left[
      \begin{array}{ccc}
        \frac{1}{\lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \frac{1}{\lambda_{N_n}}
      \end{array}
    \right] U^T \\
\]
therefore:
\begin{align*}
  G_i & = U \: \Lambda^{-1} \: U^T \left(U \: e^{\Lambda \triangle t_i} \: U^T - U \: U^T \right) C^{-\frac{1}{2}} = \\
      & = U \left[
        \begin{array}{ccc}
          \frac{e^{\triangle t_i \: \lambda_1} - 1}{\lambda_1} & \cdots & 0 \\
          \vdots & \ddots & \vdots \\
          0 & \cdots & \frac{e^{\triangle t_i \: \lambda_{N_n}} - 1}{\lambda_{N_n}}
        \end{array}
      \right] U^T \: C^{-\frac{1}{2}}
\end{align*}

Therefore, in order to find SSDTC, we need to solve the following system of linear equations:
\[
  \begin{cases}
    K_1 \: Y_1 - Y_2 & = -Q_1 \\
    ... \\
    K_{N_s} \: Y_{N_s} - Y_{N_s + 1} & = -Q_{N_s}
  \end{cases}
\]
where $Q_i = G_i \: B_i$. Also we should take into account the boundary condition which ensures that the temperature has the same values on both sides of the curve:
\begin{equation} \label{eq:boundary-condition}
  Y_1 = Y_{N_s + 1}
\end{equation}

Hence, the system of linear equations takes the following form:
\[
  \begin{cases}
    K_1 \: Y_1 - Y_2 & = -Q_1 \\
    ... \\
    -Y_1 + K_{N_s} \: Y_{N_s} & = -Q_{N_s}
  \end{cases}
\]

To get the whole picture, the system can be written as:
\begin{align}
  & \mathbb{A} \: \mathbb{Y} = \mathbb{B} \label{eq:system} \\
  & \mathbb{A} = \left[
    \begin{array}{ccccc}
      K_1 & -I & 0 & \cdots & 0 \\
      0 & K_2 & -I &  & \vdots \\
      \vdots &  & \ddots & -I & 0 \\
      0 &  &  & K_{N_s - 1} & -I \\
      -I & 0 & \cdots & 0 & K_{N_s}
    \end{array}
  \right] \nonumber \\
  & \mathbb{Y} = \left[
    \begin{array}{c}
      Y_1 \\
      \vdots \\
      Y_{N_s}
    \end{array}
  \right] \nonumber \\
  & \mathbb{B} = \left[
    \begin{array}{c}
      -Q_1 \\
      \vdots \\
      -Q_{N_s}
    \end{array}
  \right] \nonumber
\end{align}

$\mathbb{A}$ is a square matrix of the dimensions $N_n N_s \times N_n N_s$. $\mathbb{Y}$ and $\mathbb{B}$ are vectors of the length $N_n N_s$. This is the system that can give us the desired SSDTP.

Such systems could be extremely big, especially when we want to achieve a high level of accuracy and, therefore, the power profile contains a lot of steps $N_s$. Each new step is $N_n$ new equations in the system given by \equref{eq:system}. Also the complexity grows very rapidly with the number of processing elements $N_p$, since in the HotSpot thermal model the number of thermal nodes $N_n$ is dependent on it according to the equation \cite{rao2008}:
\[
  N_n = 4 N_p + 12
\]

Therefore, \emph{each} new processing element increases \emph{each} matrix $K_i$ by 4 rows and 4 columns, and \emph{each} vector $Y_i$ and $Q_i$ by 4 elements. All in all, a fast and accurate approach to solve \equref{eq:system} is required.

\subsection{Condensed Equation}
The system that we have is described with the following recurrent equation:
\begin{equation} \label{eq:ce-recurrent}
  Y_{i + 1} = K_i \: Y_i + Q_i, \; i = 1 \dots N_s
\end{equation}

The iterative repetition of this equation leads us to:
\begin{align}
  Y_i & = \prod_{j = 1}^{i} K_j \: Y_1 + P_{i - 1}, \; i = 2 \dots N_s + 1 \label{eq:y-recurrent} \\
  P_1 & = Q_1 \nonumber \\
  P_i & = \sum_{l = 2}^i \prod_{j = l}^i K_j \: Q_{l - 1} + Q_i, \: i = 2 \dots N_s \nonumber
\end{align}

The recurrent version of the last equation:
\begin{equation} \label{eq:p-recurrent}
  P_i = K_i \: P_{i - 1} + Q_i, \; i = 2 \dots N_s
\end{equation}

Therefore, we can calculate the final value $Y_{N_s + 1}$ from \equref{eq:y-recurrent}:
\[
  Y_{N_s + 1} = \prod_{j = 1}^{N_s} K_j \: Y_1 + P_{N_s}
\]

Taking into account the boundary condition given by \equref{eq:boundary-condition}, we obtain the following system of linear equations:
\[
  (I - \prod_{j = 1}^{N_s} K_j) \: Y_1 = P_{N_s}
\]

Solving this system, we obtain the first component of the vector $\mathbb{Y}$, that is $Y_1$. ($P_{N_s}$ can be calculated using \equref{eq:p-recurrent}.) All other vectors $Y_i$ for $i = 2 \dots N_s$ are successively found with help of \equref{eq:ce-recurrent}. We also recall that $K_i$ is the matrix exponential, therefore, we use the following simplification:
\[
  \prod_{j = i}^l K_j = \prod_{j = i}^l e^{D t_j} = e^{D \sum_{j = i}^l t_j}
\]
since the product of each pair $D \: t_j$ and $D \: t_k$ is commutative.

\subsection{Sampling Interval}
Now, we make an important assumption about the time intervals $\triangle t_i$ in order to perform all the calculations in a much more efficient manner. We assume that \emph{the time intervals are equal}, $\triangle t_i = \triangle t$ for $i = 1 \dots N_s$, i.e., the distance in time between two successive power measurements stays constant. We refer to this distance as \emph{sampling interval}. The preferable size of this sampling interval depends on a particular application and the level of accuracy that we want to achieve. Having this assumption, the iterative process (\equref{eq:recurrent-equation}) turns into:
\[
  Y_{i+1} = K \: Y_i + G \: B_i
\]
where:
\begin{align*}
  & K = e^{D \: \triangle t} \\
  & G = D^{-1} \left( e^{D \: \triangle t} - I \right) C^{-\frac{1}{2}}
\end{align*}

It should be noted that $K$ and $G$ are constants, since they depend only on the matrices $D$, $C$, and the sampling interval $\triangle t$. Both $Y_i$ and $B_i$ are vectors of the length $N_n$. In this case, the block diagonal of the matrix $\mathbb{A}$ in \equref{eq:system} is composed of the same block, since $K_i = K$ for $i = 1 \dots N_s$.

Let us come back to the condensed equation presented in the previous section. The recurrent expressions in case of equal time intervals are the following:
\begin{align}
  & Y_{i + 1} = K \: Y_i + Q_i, \; i = 1 \dots N_s \nonumber \\
  & P_i = K \: P_{i - 1} + Q_i, \; i = 2 \dots N_s \nonumber \\
  & (I - K^{N_s}) Y_1 = P_{N_s} \label{eq:linear-system}
\end{align}

Again thank to the matrix exponential $K$ and eigenvalue decomposition, $K^{N_s}$ can be found very efficiently:
\begin{align*}
  K^{N_s} & = U \: e^{N_s \triangle t \: \Lambda} \: U^T = U \: e^{\mathcal{T} \Lambda} \: U^T \\
    & = U \left[
      \begin{array}{ccc}
        e^{\mathcal{T} \lambda_1} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{\mathcal{T} \lambda_{N_n}}
      \end{array}
    \right] U^T
\end{align*}
where $U$ is a square matrix of the eigenvectors (orthogonal) of $D \triangle t$, $\Lambda$ is a diagonal matrix of the eigenvalues, and $\mathcal{T}$ is the period of the application.

Substituting $K^{N_s}$ from the last equation into \equref{eq:linear-system}, we get:
\[
  (I - U \: e^{\mathcal{T} \Lambda} \: U^T) Y_1 = P_{N_s}
\]

The identity matrix $I$ can be thought as $U U^T$, therefore:
\begin{align*}
  & U (I - e^{\mathcal{T} \Lambda}) U^T \: Y_1 = P_{N_s} \\
  & Y_1 = U (I - e^{\mathcal{T} \Lambda})^{-1} U^T P_{N_s} \\
  & Y_1 = U M U^T P_{N_s}
\end{align*}
where $M$ is a diagonal matrix with the following structure:
\[
  M = \left[
    \begin{array}{ccc}
      \frac{1}{1 - e^{\mathcal{T} \lambda_1}} & \cdots & 0 \\
      \vdots & \ddots & \vdots \\
      0 & \cdots & \frac{1}{1 - e^{\mathcal{T} \lambda_{N_n}}}
    \end{array}
  \right]
\]

As we see, in this approach there is no need to inverse any matrix, the solution of the system is obtained by scalar divisions and a similarity transformation with $U$.
