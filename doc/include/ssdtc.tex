\subsection{Problem Formulation}
We consider a multiprocessor embedded system that runs a number of periodic tasks. We assume that the power profile of the system is given, and it has periodic nature. Therefore, the overall profile is described with one repeating chunk.

In this case, after the stabilization process, the temperature profile also becomes periodic. This temperature curve is called \ssdtc\ (SSDTC), and our goal is to find it. Furthermore, we want to calculate it quick and accurate enough to be able to use it inside other optimization problems. An example of such problem is given in \secref{sec:results}.

\subsection{Iterative Solution with HotSpot}
One approach to find SSDTC would be to call HotSpot (the tool) with a very long power profile composed of some repeating chunk, but it would take much time to compute (see the comparison in \secref{sec:results}).

\subsection{Direct Analytical Solution}
In order to deal with the problem, we use the analytical approach. First of all, we need to be able to solve \equref{eq:initial} efficiently. The direct solution is:
\begin{equation} \label{eq:solution}
  T(t) = e^{C^{-1}A \cdot t} \cdot T_0 + (C^{-1} \cdot A)^{-1}(e^{C^{-1}A \cdot t} - I)C^{-1} \cdot B
\end{equation}

Here we need to find the matrix exponential of $C^{-1} \cdot A \cdot t$, but it would be easier to do if the matrix were symmetric, because a real symmetric matrix is diagonalizable and has independent (orthogonal) real eigenvectors:
\begin{align}
  & A = U \cdot \Lambda \cdot U^T \label{eq:eigenvalue-decomposition} \\
  & e^A = e^{U \cdot \Lambda \cdot U^T} = U \cdot e^{\Lambda} \cdot U^T \nonumber \\
  & e^{\Lambda} = \left[
      \begin{array}{ccc}
        e^{\lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{\lambda_{n - 1}}
      \end{array}
    \right] \nonumber
\end{align}
where: $A$ is a real symmetric matrix, $U$ is the eigenvectors of $A$, $\Lambda$ is a diagonal matrix of the eigenvalues of $A$ ($\lambda_i$).

Therefore, we want to keep symmetry of the matrix which matrix exponential we are going to compute. In order to achieve this, we do the following substitution:
\begin{align*}
  Y & = C^{\frac{1}{2}} \cdot T \\
  D & = C^{-\frac{1}{2}} \cdot A \cdot C^{-\frac{1}{2}} \\
  E & = C^{-\frac{1}{2}} \cdot B
\end{align*}
with the result:
\begin{align}
  \frac{dY}{dt} & = D \cdot Y + E \nonumber \\
  Y(t) & = e^{D \cdot t} \cdot Y_{0} + D^{-1}(e^{D \cdot t} - I)E \label{eq:modified-solution} \\
  T(t) & = C^{-\frac{1}{2}} \cdot Y(t) \nonumber
\end{align}

Now $D$ is a symmetric matrix, hence, it will be easy to find the matrix exponential of $D \cdot t$ using the eigenvalue decomposition (\equref{eq:eigenvalue-decomposition}):
\[
  e^{D \cdot t} = U \cdot e^{t \cdot \Lambda} \cdot U^T = \left[
      \begin{array}{ccc}
        e^{t \cdot \lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & e^{t \cdot \lambda_{n - 1}}
      \end{array}
    \right]
\]

Each line of the power profile $B$ contains power values for all cores, denoted as $B_i$, at the same period of time $t_i$. Each step of the iterative process we get a vector of temperature values for all cores according to \equref{eq:modified-solution}:
\begin{align}
  & Y_{i+1} = K_i \cdot Y_i + G_i \cdot B_i \label{eq:ce-recurrent} \\
  & K_i = e^{D \cdot t_i} \nonumber \\
  & G_i = D^{-1}(e^{D \cdot t_i} - I) C^{-\frac{1}{2}} \nonumber
\end{align}

Since we perform the eigenvalue decomposition of D (\equref{eq:eigenvalue-decomposition}), $D^{-1}$ can be efficiently computed in the following way:
\[
  D^{-1} = U \cdot \Lambda^{-1} \cdot U^T = U \left[
      \begin{array}{ccc}
        \frac{1}{\lambda_0} & \cdots & 0 \\
        \vdots & \ddots & \vdots \\
        0 & \cdots & \frac{1}{\lambda_{n - 1}}
      \end{array}
    \right] U^T \\
\]
therefore:
\begin{align*}
  G_i & = U \cdot \Lambda^{-1} \cdot U^T (U \cdot e^{t_i \cdot \Lambda} \cdot U^T - U \cdot U^T) C^{-\frac{1}{2}} = \\
      & = U \left[
        \begin{array}{ccc}
          \frac{e^{t_i \cdot \lambda_0} - 1}{\lambda_0} & \cdots & 0 \\
          \vdots & \ddots & \vdots \\
          0 & \cdots & \frac{e^{t_i \cdot \lambda_{n - 1}} - 1}{\lambda_{n - 1}}
        \end{array}
      \right] U^T \cdot C^{-\frac{1}{2}}
\end{align*}

If the time intervals are equal, i.e. the distance in time between two vectors of power values stays the same, the iterative process can be described as the following:
\[
  Y_{i+1} = K \cdot Y_i + G \cdot B_i
\]
where:
\begin{align*}
  & t_i = t_s, \forall i \\
  & K = e^{D \cdot t_s} \\
  & G = D^{-1}(e^{D \cdot t_s}-I) C^{-\frac{1}{2}}
\end{align*}

It should be noted that $K$ and $G$ are constants, since they depend only on the matrices $A$, $C$, and the sampling interval $t_s$.  Both $Y_i$ and $B_i$ are vectors $n \times 1$.

Therefore, in order to find SSDTC, we need to solve the following system of linear equations:
\[
  \begin{cases}
    K_0 \cdot Y_0 - Y_1 & = -Q_0 \\
    ... \\
    K_{m-1} \cdot Y_{m-1} - Y_{m} & = -Q_{m-1}
  \end{cases}
\]
where $Q_i = G_i \cdot B_i$.

Also we have one boundary condition that ensures the temperature to be the same on both sides of the curve:
\begin{equation} \label{eq:boundary-condition}
  Y_0 = Y_m
\end{equation}

Taking it into account, we get:
\[
  \begin{cases}
    K_0 \cdot Y_0 - Y_1 & =-Q_0 \\
    ... \\
    -Y_0 + K_{m-1} \cdot Y_{m-1} & = -Q_{m-1}
  \end{cases}
\]

In this notation, the system can be written as:
\begin{align}
  & AA \cdot YY = BB \label{eq:system} \\
  & AA = \left[
    \begin{array}{ccccc}
      K_0 & -I & 0 & \cdots & 0 \\
      0 & K_1 & -I &  & \vdots \\
      \vdots &  & \ddots & -I & 0 \\
      0 &  &  & K_{m-2} & -I \\
      -I & 0 & \cdots & 0 & K_{m-1}
    \end{array}
  \right] \nonumber \\
  & YY = \left[
    \begin{array}{c}
      Y_0 \\
      Y_1 \\
      \vdots \\
      Y_{m-2} \\
      Y_{m-1}
    \end{array}
  \right] \nonumber \\
  & BB = \left[
    \begin{array}{c}
      -Q_0 \\
      -Q_1 \\
      \vdots \\
      -Q_{m-2} \\
      -Q_{m-1}
    \end{array}
  \right] \nonumber
\end{align}

$AA$ is a square matrix $nm \times nm$. $YY$ and $BB$ are vectors $nm \times 1$. This is the system that can give us desired SSDTC. It should be observed that if the sampling interval is constant, the block diagonal of the matrix $AA$ is composed of the same blocks $K$.

Such systems could be extremely big, therefore, we need to find a fast and accurate way to solve them.

\subsection{Condensed Equation Method}
The system that we have is described with the following recurrent equation:
\begin{equation} \label{eq:recurrent}
  Y_{i + 1} = K_i \cdot Y_i + Q_i, \; i = 0 \dots (m - 1)
\end{equation}

The iterative repetition of this equation leads us to:
\begin{align}
  Y_i & = \prod_{j = 0}^{i - 1} K_j \cdot Y_0 + P_{i - 1}, \; i = 1 \dots m \label{eq:y-recurrent} \\
  P_0 & = Q_0 \nonumber \\
  P_i & = \sum_{l = 1}^i \prod_{j = l}^i K_j \cdot Q_{l - 1} + Q_i, \: i = 1 \dots (m - 1) \nonumber
\end{align}
The last one can be rewritten as:
\begin{equation} \label{eq:p-recurrent}
  P_i = K_i \cdot P_{i - 1} + Q_i, \; i = 1 \dots (m - 1)
\end{equation}

Therefore, we can calculate the final value $Y_m$ from \equref{eq:y-recurrent}:
\[
  Y_m = \prod_{j = 0}^{m - 1} K_j \cdot Y_0 + P_{m - 1}
\]

Taking into account the boundary condition \equref{eq:boundary-condition} and substituting $Y_m$ with $Y_0$, we get the following system of linear equations:
\[
  (I - \prod_{j = 0}^{m - 1} K_j) Y_0 = P_{m - 1}
\]

To solve it, we need to obtain $P_{m - 1}$ from \eqref{eq:p-recurrent}. Once we get $Y_0$, we can use \eqref{eq:recurrent} to get all other vectors $Y_i$.

Now, we know that in case of the fixed sampling interval $K_i = K$. Therefore, the equations become much simpler:
\begin{align}
  & Y_{i + 1} = K \cdot Y_i + Q_i, \; i = 0 \dots (m - 1) \nonumber \\
  & P_i = K \cdot P_{i - 1} + Q_i, \; i = 1 \dots (m - 1) \nonumber \\
  & (I - K^m) Y_0 = P_{m - 1} \label{eq:linear-system}
\end{align}

In this case, $K^m$ can be found very efficiently, since it is a power of the matrix exponential of $D t_s$ (see \equref{eq:ce-recurrent}):
\begin{align*}
  & K = U \cdot e^{\Lambda} \cdot U^T = U \cdot diag(\lambda_0, \dots, \lambda_{n - 1}) \cdot U^T \\
  & K^m = U \cdot e^{\Lambda} \cdot U^T \cdot U e^{\Lambda} \cdot U^T \dots U \cdot e^{\Lambda} \cdot U^T = U \cdot e^{m \Lambda} \cdot U^T
\end{align*}
where $U$ is a matrix of the eigenvectors of $D t_s$ (orthogonal), $\Lambda$ is a diagonal matrix of the eigenvalues of $D t_s$.

Substituting $K^m$ from the last equation into \equref{eq:linear-system}, we get:
\[
  (I - U \cdot e^{m \cdot \Lambda} \cdot U^T) Y_0 = P_{m - 1}
\]

The identity matrix $I$ can be split into $U U^T$, therefore:
\begin{align*}
  & U (I - e^{m \cdot \Lambda}) U^T \cdot Y_0 = P_{m - 1} \\
  & Y_0 = U (I - e^{m \cdot \Lambda})^{-1} U^T \cdot P_{m - 1} \\
  & Y_0 = U \cdot M \cdot U^T \cdot P_{m - 1}
\end{align*}
where $M$ is a diagonal matrix with the following structure:
\[
  M = \left[
    \begin{array}{ccc}
      \frac{1}{1 - e^{m \cdot \lambda_0}} & \cdots & 0 \\
      \vdots & \ddots & \vdots \\
      0 & \cdots & \frac{1}{1 - e^{m \cdot \lambda_{n - 1}}}
    \end{array}
  \right]
\]

As we see, in this approach there is no need to inverse any matrix, the solution of the system is obtained by scalar divisions and a similarity transformation with $U$.

We also can benefit from the matrix exponential in the general case where the time intervals could be different:
\[
  \prod_{j = i}^l K_j = \prod_{j = i}^l e^{D \cdot t_j} = e^{D \sum_{j = i}^l t_j}
\]
since the product of each pair $D \cdot t_j$ and $D \cdot t_k$ is commutative.
